{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 12, 12, 64)        0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 128)               1179776   \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                1290      \n=================================================================\nTotal params: 1,199,882\nTrainable params: 1,199,882\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/20\n44160/60000 [=====================>........] - ETA: 38s - loss: 0.4193 - acc: 0.8733"
                }
            ], 
            "source": "from keras.datasets import mnist  # mnist datasets contains 60,000 train sample and 10,000 sample for tests and each individual sample is 28*28 pixels\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import SGD  \nfrom keras.optimizers import Adadelta  \nfrom keras.utils import to_categorical \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout,Flatten  #Flatten is the layer which reduces the dimensionality of a Tensor  \nfrom keras.layers import Conv2D, MaxPooling2D  # Conv2D which perfectly fits two dimensional image data, MaxPooling2D layer is to contain pooling data which is also in 2D.\nfrom keras import backend as K  # K is nothing but instance of TensorFlow backend \n\n\nbatch_size = 128  # batch_size will be used in forward pass and also for predictions \nnum_classes = 10  # number of output labels or classes in output layer \nepochs = 20  # we are going to train the neural network for 20 epochs in total \n\n#input image dimensions \nimg_rows=28\nimg_cols=28\nAdadelta=Adadelta();\n\n# loading data \n(x_train,y_train),(x_test,y_test) = mnist.load_data() # load data method will retreive training dataset and testinng dataset as well \n\n# as x_train,X-test contains only 28*28 pixel images.\n\n# Data preprocessing \nif K.image_data_format() == 'channels_first':  # that means based on the backend architecture we are mentioning order of  height and width and number of color channels \n    x_train=x_train.reshape(x_train.shape[0],1,img_rows,img_cols) # 1 is because image is mono-chrome image not a color image(grayscale image)\n    x_test=x_test.reshape(x_test.shape[0],1,img_rows,img_cols)\n    input_shape=(1,img_rows,img_cols)   \nelse:\n    x_train=x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n    x_test=x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n    input_shape=(img_rows,img_cols,1) \n\n\n    \nx_train=x_train.astype('float32') \nx_test=x_test.astype('float32')\n# to make 0 to 255 values to be lied in 0 to 1 \n\nx_train /= 255\nx_test /=255\n\n# onehot encoding for output labels \ny_train=to_categorical(y_train,num_classes) # functionality:  if we have label with the number 0 on it, this is going to be transformed into a vector of length 10 that has all zeros but 1 at 0th place in a vector as label is 0\ny_test=to_categorical(y_test,num_classes)\n\n# Defining and compiling your model\nmodel=Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=input_shape))  # First Convolution layer here kernel_size is convolutional matrix size \n\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu'))  # Second convolution layer should have more neurons then first convolution layer \n\nmodel.add(MaxPooling2D(pool_size=(2,2))) # here 2*2 matrix iterates over the convolution data and mimimizes by selecting maximum value in 2*2 matrix \n\nmodel.add(Dropout(0.25)) # to drop the 25 percentage of neurons in 2nd convoultion layer \n\nmodel.add(Flatten()) # this is to reduce the dimension of 28*28*1 images into 784 vectors \n\n\n\nmodel.add(Dense(128, activation='relu')) # This is the fully connected layer \n\nmodel.add(Dropout(0.5)) # to drop the 50 percentage of neurons in Fully connected layer \n\nmodel.add(Dense(num_classes, activation='softmax')) # This is the fully connected layer \n\nmodel.summary()\n\nmodel.compile(loss=categorical_crossentropy, # categorical_crossentrophy is very good fit for multiclass clasification \n             optimizer=Adadelta,\n             metrics=['accuracy'])   # Compiling model by specifying loss(cost) function and loss optimizer as sgd \n\n\n# Running and evaluating your model \nmodel.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test,y_test))  # Training model \n\n# Evaluating or Testing model \nscore=model.evaluate(x_test,y_test,verbose=0)\n\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
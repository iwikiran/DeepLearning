{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_10 (Dense)             (None, 512)               401920    \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 512)               262656    \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 10)                5130      \n=================================================================\nTotal params: 669,706\nTrainable params: 669,706\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/20\n60000/60000 [==============================] - 5s - loss: 0.4919 - acc: 0.8579 - val_loss: 0.2199 - val_acc: 0.9364\nEpoch 2/20\n60000/60000 [==============================] - 5s - loss: 0.2192 - acc: 0.9357 - val_loss: 0.1494 - val_acc: 0.9563\nEpoch 3/20\n60000/60000 [==============================] - 5s - loss: 0.1632 - acc: 0.9523 - val_loss: 0.1205 - val_acc: 0.9642\nEpoch 4/20\n60000/60000 [==============================] - 6s - loss: 0.1305 - acc: 0.9611 - val_loss: 0.1060 - val_acc: 0.9675\nEpoch 5/20\n60000/60000 [==============================] - 6s - loss: 0.1107 - acc: 0.9672 - val_loss: 0.0932 - val_acc: 0.9703\nEpoch 6/20\n60000/60000 [==============================] - 5s - loss: 0.0956 - acc: 0.9720 - val_loss: 0.0830 - val_acc: 0.9738\nEpoch 7/20\n60000/60000 [==============================] - 5s - loss: 0.0818 - acc: 0.9756 - val_loss: 0.0766 - val_acc: 0.9746\nEpoch 8/20\n60000/60000 [==============================] - 5s - loss: 0.0745 - acc: 0.9778 - val_loss: 0.0720 - val_acc: 0.9769\nEpoch 9/20\n60000/60000 [==============================] - 5s - loss: 0.0671 - acc: 0.9796 - val_loss: 0.0695 - val_acc: 0.9780\nEpoch 10/20\n60000/60000 [==============================] - 5s - loss: 0.0601 - acc: 0.9822 - val_loss: 0.0679 - val_acc: 0.9785\nEpoch 11/20\n60000/60000 [==============================] - 5s - loss: 0.0546 - acc: 0.9834 - val_loss: 0.0638 - val_acc: 0.9797\nEpoch 12/20\n60000/60000 [==============================] - 5s - loss: 0.0504 - acc: 0.9843 - val_loss: 0.0614 - val_acc: 0.9801\nEpoch 13/20\n60000/60000 [==============================] - 5s - loss: 0.0474 - acc: 0.9853 - val_loss: 0.0601 - val_acc: 0.9806\nEpoch 14/20\n60000/60000 [==============================] - 5s - loss: 0.0421 - acc: 0.9875 - val_loss: 0.0623 - val_acc: 0.9791\nEpoch 15/20\n60000/60000 [==============================] - 5s - loss: 0.0392 - acc: 0.9884 - val_loss: 0.0600 - val_acc: 0.9803\nEpoch 16/20\n11264/60000 [====>.........................] - ETA: 5s - loss: 0.0330 - acc: 0.9896"
                }
            ], 
            "source": "from keras.datasets import mnist  # mnist datasets contains 60,000 train sample and 10,000 sample for tests and each individual sample is 28*28 pixels\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import SGD  \nfrom keras.utils import to_categorical \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout \n\nbatch_size = 128  # batch_size will be used in forward pass and also for predictions \nnum_classes = 10  # number of output labels or classes in output layer \nepochs = 20  # we are going to train the neural network for 20 epochs in total \n\nsgd=SGD(lr=0.01, # lr is learning rate \n       decay=1e-6, # to decrease the learning rate after each parameter update\n       momentum=0.9)   \n# loading data \n(x_train,y_train),(x_test,y_test) = mnist.load_data() # load data method will retreive training dataset and testinng dataset as well \n\n# as x_train,X-test contains only 28*28 pixel images.\n\n# Data preprocessing \n# Flattening 60000 training images to 60000 784 vectors to feed them into dense layer \nx_train=x_train.reshape(60000,784)\n# Flattening 10000 training images to 60000 784 vectors \nx_test=x_test.reshape(10000,784)\nx_train=x_train.astype('float32') \nx_test=x_test.astype('float32')\n# to make 0 to 255 values to be lied in 0 to 1 \n\nx_train /= 255\nx_test /=255\n\n# onehot encoding for output labels \ny_train=to_categorical(y_train,num_classes) # functionality:  if we have label with the number 0 on it, this is going to be transformed into a vector of length 10 that has all zeros but 1 at 0th place in a vector as label is 0\ny_test=to_categorical(y_test,num_classes)\n\n# Defining and compiling your model\nmodel=Sequential()\nmodel.add(Dense(512, activation='relu', input_shape=(784,))) # First layer only # input_shape should be provided for first layer only input_shape is nothing but length of input vectors eg: 784 \nmodel.add(Dropout(0.2)) # to drop the 20 percentage of neurons in the first layer \nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2)) # to drop the 20 percentage of neurons in the second layer \nmodel.add(Dense(num_classes,activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss=categorical_crossentropy,\n             optimizer=sgd,\n             metrics=['accuracy'])   # Compiling model by specifying loss(cost) function and loss optimizer as sgd \n\n\n# Running and evaluating your model \nmodel.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test,y_test))  # Training model \n\n# Evaluating or Testing model \nscore=model.evaluate(x_test,y_test,verbose=0)\n\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0.9167\nWeights are :<tf.Variable 'Variable_14:0' shape=(784, 10) dtype=float32_ref>\nBiases are;<tf.Variable 'Variable_15:0' shape=(10,) dtype=float32_ref>\n"
                }
            ], 
            "source": "\nimgdata=tf.placeholder(tf.float32,[None,784])\nweights=tf.Variable(tf.zeros([784,10])) # as there are we need to display 10 outputs(softmix softregression model each model will have 784 weights and all weights are initialized to 0)\nbias=tf.Variable(tf.zeros([10]))      # as each output neuron will have bias we need to give 10 biases as there are 10 outputs(softmix regression model)\ncomputed_output=tf.nn.softmax(tf.matmul(imgdata,weights)+bias)   #matmul is nothing but matrix multiplication and softmax will return final output \ndesired_outptut=tf.placeholder(tf.float32,[None,10])   # this vector contains actual output labels \n\n#cross-entrophy is like -CaptialSigmai actualoutput(i)*log(desiredoutput(i))\n\n# here we are going to calculate 10 cross entrophy values 1 for each softmax regression model\ncross_entrophy=tf.reduce_mean(-tf.reduce_sum(desired_outptut*tf.log(computed_output),reduction_indices=[1]))  # this will calculate the invidual prediction erros for numbers between 0 and 9 \ntrain_step=tf.train.GradientDescentOptimizer(0.5).minimize(cross_entrophy)  # this will automatically calculates gradients with the learning rate of 0.5 and by taking cross_entrophy to change weigths and baises\nsess=tf.InteractiveSession() # sesssion is the way to deploy a TensorFlow execution graph, on to specific execution context like a CPU or GPU.\ntf.global_variables_initializer().run() # intialize all global variables \nfor _ in range(1000):  # here we are iterating 1000 times and \n    batch_xs,batch_ys=mnist.train.next_batch(100) # this will return 100 randomly selected images \n    sess.run(train_step,feed_dict={imgdata: batch_xs,desired_outptut: batch_ys})\n    \ncorrect_prediction=tf.equal(tf.argmax(computed_output,1),tf.argmax(desired_outptut,1))  # it compares desired output with computed output and returns Boolean value\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) # to return accuracy in terms of percentages \n\nprint(sess.run(accuracy,feed_dict={imgdata: mnist.test.images, desired_outptut: mnist.test.labels}))\n    "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}